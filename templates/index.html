<!-- 
    とりあえず、口パクの画像切り換えに挑戦するも、それすらも上手くいかない。
-->
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>AIチャットインターフェース15</title>
    <!-- Bootstrap 5.3.0-alpha1 CSS追加 -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- integrity 属性を削除 -->
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js" crossorigin="anonymous"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f2f5;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start;
            height: 100vh;
            margin: 0;
        }
        #voice-start-btn:disabled {
            background-color: #b8daff !important;
            color: #fff !important;
            border-color: #b8daff !important;
        }
        #voice-stop-btn:disabled {
            background-color: #e2e3e5 !important;
            color: #aaa !important;
            border-color: #e2e3e5 !important;
        }
        #chat { 
            width: 80%; 
            max-width: 800px; 
            margin: 20px auto; 
            border: 1px solid #ccc; 
            padding: 10px; 
            height: 400px; 
            overflow-y: scroll; 
            background-color: #fff;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
            border-radius: 5px;
        }
        .message { 
            padding: 10px; 
            margin: 5px 0; 
            border-radius: 5px; 
            max-width: 70%;
            word-wrap: break-word;
        }
        .user { 
            background-color: #d1e7dd; 
            text-align: right; 
            margin-left: auto;
        }
        .ai { 
            background-color: #f8d7da; 
            text-align: left; 
            margin-right: auto;
        }
        #status { 
            width: 80%; 
            max-width: 800px; 
            margin: 10px auto; 
            font-size: 0.9em; 
            color: gray; 
            height: 100px; 
            overflow-y: scroll; 
            border: 1px solid #ccc; 
            padding: 5px; 
            background-color: #f1f1f1;
            box-shadow: 0 0 5px rgba(0,0,0,0.05);
            border-radius: 5px;
        }
        /* AIアバター用のスタイル */
        #ai-avatar-container {
            position: relative;
            width: 150px;
            height: 150px;
            margin-bottom: 10px;
        }
        #ai-avatar {
            width: 100%;
            height: 100%;
        }
    </style>
    <style>
        /* interim仮認識の吹き出しを薄色に */
        .user.user-interim {
            opacity: 0.5;
        }
    </style>
</head>
<body>
    <!-- AIアバター表示エリア -->
    <div id="ai-avatar-container">
        <img id="ai-avatar" src="/static/ai_avatar_closed.png" alt="AI Avatar">
    </div>
    <!-- インタビュー開始ボタン -->
    <div class="mb-3" style="margin: 10px 0;">
        <button id="start-btn" class="btn btn-primary">インタビュー開始</button>
    </div>
    <div id="chat"></div>
    <div id="status"></div>
    <!-- 音声入力コントロール -->
    <div class="mb-3" style="margin: 10px 0;">
        <button id="voice-start-btn" class="btn btn-success me-2">話し始める</button>
        <button id="voice-stop-btn" class="btn btn-danger" disabled>話し終える</button>
    </div>

    <script>
        const socket = io();
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        async function initAudio() {
            try {
                await navigator.mediaDevices.getUserMedia({ audio: true });
                if (audioContext.state === "suspended") {
                    await audioContext.resume();
                }
                console.log("マイク許可取得 & AudioContext resumed: 音声再生が解禁されました");
            } catch (err) {
                console.error("マイク許可が拒否されました:", err);
            }
        }
        // ページロード時に呼び出す
        const startBtn = document.getElementById('start-btn');
        initAudio();

        // 録音ボタン制御
        const voiceStartBtn = document.getElementById('voice-start-btn');
        const voiceStopBtn = document.getElementById('voice-stop-btn');
        let mediaRecorder;
        let audioChunks = [];

        voiceStartBtn.addEventListener('click', async () => {
            console.log("[UI] 開始ボタン押下");
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                // 状態反映
                voiceStartBtn.classList.remove('btn-success');
                voiceStartBtn.classList.add('btn-outline-success');
                voiceStartBtn.disabled = true;
                voiceStopBtn.classList.remove('btn-outline-danger');
                voiceStopBtn.classList.add('btn-danger');
                voiceStopBtn.disabled = false;

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    console.log("[Media] 停止完了、送信処理開始");
                    if (audioChunks.length > 0) {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        const pcm16 = await wavToPCM16(audioBlob, 24000);
                        const uint8Array = new Uint8Array(pcm16.buffer);
                
                        // base64分割送信（64KBずつ）
                        const maxChunkBytes = 64000;
                        for (let offset = 0; offset < uint8Array.length; offset += maxChunkBytes) {
                            const slice = uint8Array.subarray(offset, offset + maxChunkBytes);
                            let binary = "";
                            const chunkSize = 8192;
                            for (let i = 0; i < slice.length; i += chunkSize) {
                                const sub = slice.subarray(i, i + chunkSize);
                                binary += String.fromCharCode(...sub);
                            }
                            const base64Audio = btoa(binary);
                            socket.emit('audio_data', { audio: base64Audio });
                            console.log("[Send] チャンク送信:", offset, "/", uint8Array.length);
                            await new Promise(r => setTimeout(r, 5)); // より短い間隔で連続送信
                        }
                
                        // commit送信
                        socket.emit('audio_commit');
                        console.log("[Send] audio_commit送信完了");
                        audioChunks = [];
                    }
                    if (mediaRecorder && mediaRecorder.stream) {
                        mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    }
                    mediaRecorder = null;
                };

                mediaRecorder.start();
                console.log("[Media] 録音開始");
            } catch (error) {
                console.error("[Error] 録音初期化失敗:", error);
            }
        });

        voiceStopBtn.addEventListener('click', () => {
            console.log("[UI] 停止ボタン押下");
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                console.log("[Media] 録音停止");
            }
            // サーバーにcommitを送信
            socket.emit('audio_commit');
            console.log("[Send] audio_commit送信");
            // ボタン状態リセット
            voiceStartBtn.classList.add('btn-success');
            voiceStartBtn.classList.remove('btn-outline-success');
            voiceStartBtn.disabled = false;
            voiceStopBtn.classList.add('btn-outline-danger');
            voiceStopBtn.classList.remove('btn-danger');
            voiceStopBtn.disabled = true;
        });

        // WAV→PCM16(24kHz, mono, little-endian)変換関数（グローバルスコープに移動）
        async function wavToPCM16(audioBlob, targetSampleRate = 24000) {
            const arrayBuffer = await audioBlob.arrayBuffer();
            const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
            // モノラル
            const rawData = audioBuffer.getChannelData(0);
            // サンプリングレート変換
            let resampled;
            if (audioBuffer.sampleRate !== targetSampleRate) {
                const ratio = audioBuffer.sampleRate / targetSampleRate;
                const newLength = Math.floor(rawData.length / ratio);
                resampled = new Float32Array(newLength);
                for (let i = 0; i < newLength; i++) {
                    resampled[i] = rawData[Math.floor(i * ratio)];
                }
            } else {
                resampled = rawData;
            }
            // PCM16変換
            const pcm16 = new Int16Array(resampled.length);
            for (let i = 0; i < resampled.length; i++) {
                let s = Math.max(-1, Math.min(1, resampled[i]));
                pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return pcm16;
        }

        async function startRecordingLoop() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    if (audioChunks.length > 0) {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        const pcm16 = await wavToPCM16(audioBlob, 24000);
                        const uint8Array = new Uint8Array(pcm16.buffer);
                        let binary = '';
                        for (let i = 0; i < uint8Array.length; i++) {
                            binary += String.fromCharCode(uint8Array[i]);
                        }
                        const base64Audio = btoa(binary);
                        // サーバーへ送信
                        socket.emit('audio_data', { audio: base64Audio });
                        audioChunks = [];
                    } else {
                        // バッファが空なら送信しない
                        console.log('録音バッファが空のため送信スキップ');
                    }
                    // 録音再開
                    if (isRecording) {
                        setTimeout(() => {
                            if (mediaRecorder.state !== 'recording') {
                                mediaRecorder.start();
                            }
                        }, 100);
                    }
                };

                // 録音ループ
                function recordCycle() {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                    }
                }

                // 最初の録音開始
                isRecording = true;
                mediaRecorder.start();
                // 5秒ごとに録音停止→onstopで再開
                recordingInterval = setInterval(recordCycle, 20000);

                window.addEventListener('beforeunload', () => {
                    isRecording = false;
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                    }
                    if (recordingInterval) {
                        clearInterval(recordingInterval);
                    }
                });
            } catch (err) {
                console.error('音声録音初期化エラー:', err);
            }
        }
        // ページロード時には録音ループを開始しない（ボタンで制御する方式に変更）
        // startRecordingLoop();
        console.log("[Init] 録音ループ自動開始を停止しました。ボタン操作で録音を開始します。");

        // AIアバターの口の動きを、テキストの長さに合わせて保持する関数
        function animateAvatarForText(text) {
            const avatarImg = document.getElementById('ai-avatar');
            // 口を開く
            avatarImg.src = "/static/ai_avatar_open.png";
            // 例として、最低1秒＋1文字あたり200msに設定（必要に応じて調整）
            const duration = 1000 + text.length * 200;
            setTimeout(() => {
                avatarImg.src = "/static/ai_avatar_closed.png";
            }, duration);
        }

        // AI応答を受信して赤い吹き出しを表示
        // AIメッセージ受信時は必ずaddAIMessageのみ呼ぶ
        socket.on('ai_message', (data) => {
            if (data && data.message) {
                addAIMessage(data.message);
            }
        });

        const messages = [];

        function insertMessage(role, text, timestamp) {
            const chat = document.getElementById('chat');
            const msgDiv = document.createElement('div');
            msgDiv.className = 'message ' + role;
            msgDiv.textContent = text;

            const msg = { role: role, text: text, timestamp: timestamp || Date.now() };
            messages.push(msg);
            messages.sort((a, b) => a.timestamp - b.timestamp);

            // DOM内のどこに挿入すべきか探す
            const children = Array.from(chat.children);
            let inserted = false;
            for (let i = 0; i < children.length; i++) {
                const existingText = children[i].textContent;
                const matching = messages.find(m => m.text === existingText);
                if (matching && matching.timestamp > msg.timestamp) {
                    chat.insertBefore(msgDiv, children[i]);
                    inserted = true;
                    break;
                }
            }
            if (!inserted) {
                chat.appendChild(msgDiv);
            }
            chat.scrollTop = chat.scrollHeight;
        }

        // turn番号・interim対応
        function addUserMessage(message, turn, interim) {
            const chat = document.getElementById('chat');
            let msgDiv = chat.querySelector('.message.user[data-turn="' + turn + '"]');
            if (!msgDiv) {
                msgDiv = document.createElement('div');
                msgDiv.className = 'message user';
                msgDiv.setAttribute('data-turn', turn);
                chat.appendChild(msgDiv);
            }
            msgDiv.textContent = message;
            if (interim) {
                msgDiv.classList.add('user-interim');
            } else {
                msgDiv.classList.remove('user-interim');
            }
            chat.scrollTop = chat.scrollHeight;
            console.log('ユーザーのメッセージを追加しました:', message, 'turn:', turn, 'interim:', interim);
        }

        // AIの応答を表示する関数
        function addAIMessage(message) {
            const chat = document.getElementById('chat');
            const msgDiv = document.createElement('div');
            msgDiv.className = 'message ai';
            msgDiv.textContent = message;
            chat.appendChild(msgDiv);
            chat.scrollTop = chat.scrollHeight;
            console.log('AIのメッセージを追加しました:', message);
            // AIの応答に合わせてアバターの口を動かす
            animateAvatarForText(message);
        }

        // ステータスメッセージを表示する関数
        function addStatusMessage(message) {
            const status = document.getElementById('status');
            const statusMsg = document.createElement('div');
            statusMsg.textContent = message;
            status.appendChild(statusMsg);
            status.scrollTop = status.scrollHeight;
            console.log('ステータスメッセージを追加しました:', message);
        }
        // AI音声データ受信＆再生
        socket.on('audio_data', function(data) {
            // base64データをArrayBufferに変換
            const base64 = data.audio;
            const binary = atob(base64);
            const len = binary.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binary.charCodeAt(i);
            }
            // Blobを生成（WAV/PCM想定。必要に応じてMIME typeを変更）
            const blob = new Blob([bytes], { type: 'audio/wav' });
            const url = URL.createObjectURL(blob);
            // Audio要素で再生
            const audio = new Audio(url);
            audio.playbackRate = 2.0; // 再生速度を2倍に設定
            audio.play().catch(e => console.error("再生失敗:", e));
            // 再生後にURLを解放
            audio.onended = () => {
                URL.revokeObjectURL(url);
            };
        });

        socket.on('connect', () => {
            console.log('サーバーに接続しました。');
            // ユーザーの接続をチャットに表示
            addUserMessage('ユーザーが接続しました。');
        });

        socket.on('user_message', (data) => {
            console.log('ユーザーのメッセージ:', data.message, 'turn:', data.turn, 'interim:', data.interim);
            addUserMessage(data.message, data.turn || 0, data.interim || false);
        });

        // ※上記でai_messageは一本化したので、ここは削除

        socket.on('status_message', (data) => {
            console.log('ステータスメッセージ:', data.message);
            addStatusMessage(data.message);
        });

        // ユーザーからの音声入力が完了したら、ユーザーのメッセージをチャットに追加するロジックを追加することも可能です。
        // 現在はバックエンドからのメッセージのみを表示しています。
        startBtn.addEventListener('click', () => {
            socket.emit('start_process');
            startBtn.disabled = true;
            voiceStartBtn.disabled = false;
            console.log("[UI] インタビュー開始ボタン押下: start_process送信");
        });
    </script>
</body>
</html>

